{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9ba8c-e86d-46e6-9068-ec0bdf9decd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packeges\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import sqlite3\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.discovery import build\n",
    "import googleapiclient.errors\n",
    "\n",
    "\n",
    "# Building the youtube build\n",
    "API_KEY: str = \"AIzaSyANcOOmvv5fs6Gx7vKXucSelmScjx3V3Qg\"\n",
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\"\n",
    "\n",
    "\n",
    "youtube = build(\n",
    "    API_SERVICE_NAME, API_VERSION, developerKey= API_KEY)\n",
    "\n",
    "print(\"starting ...\")\n",
    "# Looding the ID's and get the statistics\n",
    "with open('../pickels/games_ids.pickle', 'rb') as f:\n",
    "    games_ids = pickle.load(f)\n",
    "    \n",
    "def get_video_stats(youtube, video_ids: list) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"This function takes the videos IDs list and request\n",
    "       for the statistics of the videos then save them into\n",
    "       a DataFrame.\"\"\"\n",
    "\n",
    "    dots = 1\n",
    "    all_video_info = []\n",
    "    videos_count = len(video_ids)\n",
    "\n",
    "    for i in range(0, videos_count, 50):\n",
    "        \n",
    "        chunk = video_ids[i:i+50]\n",
    "        processed_videos_count = i + len(chunk)\n",
    "        \n",
    "        # Giving the request for each 50 video in one time\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(chunk))\n",
    "        response = request.execute()\n",
    "        \n",
    "        # Calculate the progress with updating it.\n",
    "        \n",
    "        \n",
    "        dots += 1\n",
    "        print(f\"Loading {dots * '.'}\", end= \"\\r\")\n",
    "        \n",
    "        if dots > 5:\n",
    "            dots = 1\n",
    "            \n",
    "        time.sleep(0.001)\n",
    "\n",
    "        for video in response['items']:\n",
    "            video_json_encoder = {\"statistics\": ['viewCount', 'likeCount', 'commentCount']}\n",
    "\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for key in video_json_encoder.keys():\n",
    "                for val in video_json_encoder[key]:\n",
    "                    try:\n",
    "                        video_info[val] = video[key][val]\n",
    "                    except:\n",
    "                        video_info[val] = np.nan\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "\n",
    "    df = pd.DataFrame(all_video_info)\n",
    "    \n",
    "    return df\n",
    "\n",
    "temp_dfs = []\n",
    "\n",
    "for game_name, ids_list in games_ids.items():\n",
    "    \n",
    "    temp_df = get_video_stats(youtube, ids_list)\n",
    "    temp_df[\"game\"] = game_name\n",
    "    temp_dfs.append(temp_df)\n",
    "    \n",
    "games_df = pd.concat(temp_dfs)\n",
    "\n",
    "today = str(datetime.datetime.now().strftime('%Y-%m-%d'))\n",
    "\n",
    "games_df[\"Collecting date\"] = today\n",
    "\n",
    "\n",
    "games_df[\"likeCount\"].fillna(1, inplace= True)\n",
    "games_df[\"commentCount\"].fillna(1, inplace= True)\n",
    "games_df[\"viewCount\"].fillna(1, inplace= True)\n",
    "\n",
    "games_df[\"likeCount\"].replace(1, inplace= True)\n",
    "games_df[\"commentCount\"].replace(1, inplace= True)\n",
    "games_df[\"viewCount\"].replace(1, inplace= True)\n",
    "\n",
    "\n",
    "# Optimizing the raw data\n",
    "\n",
    "games_df.astype({\"viewCount\": np.uint32, \"likeCount\": np.uint32(), \n",
    "                 \"commentCount\": np.uint16, \"Collecting date\": 'datetime64[ns]'})\n",
    "\n",
    "\n",
    "# Saving the data using .Pickle\n",
    "try:\n",
    "    stacked_games_df = pd.read_pickle(\"../data files/stacked_games_df.pickle\")\n",
    "    stacked_games_df = pd.concat([stacked_games_df, games_df], ignore_index=True)\n",
    "    stacked_games_df.to_pickle(\"../../Cleaned files/stacked_games_df.pickle\")\n",
    "    \n",
    "except:\n",
    "    games_df.to_pickle(\"../../Cleaned files/stacked_games_df.pickle\")\n",
    "    \n",
    "    \n",
    "# Saving the data using SQLite\n",
    "\n",
    "conn = sqlite3.connect('../../database.db')\n",
    "games_df.to_sql('stacked_games', conn, if_exists= 'append', index=False)\n",
    "\n",
    "print(\"\\nDone ...\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
